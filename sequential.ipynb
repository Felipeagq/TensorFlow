{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# PREPARANDO LA DATA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTAMOS LAS LIBRERIAS \n",
    "\n",
    "import os \n",
    "import datetime \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGAMOS EL DATASET\n",
    "data = pd.read_csv('Life Expectancy Data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VEMOS LOS DATOS FALTANTES\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELIMINAMOS LA DATA FALTANTE\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFICAMOS QUE SE HAYA ELIMINADO LA DATA FALTANTE\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = data.select_dtypes(exclude='number')\n",
    "categorical_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PODEMOS ELIMIMAR LA COLUMNA data['Country']\n",
    "data.drop('Country',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTIMOS LA COLUMNA data['status'] EN NUMERICO\n",
    "status_dummy = pd.get_dummies(data['Status'])\n",
    "status_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELIMINAMOS LA DATA CATEGORICA \n",
    "data.drop('Status',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGREGAMOS LA DATA DUMMY\n",
    "data['develop'] = status_dummy['Developed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESTANDARIZAMOS NUESTRA DATA CON StandardScaler()\n",
    "\n",
    "s_scaler = StandardScaler()\n",
    "scaled_data = s_scaler.fit_transform(data)\n",
    "\n",
    "scaled_data = pd.DataFrame(scaled_data,\n",
    "columns=data.columns,\n",
    "index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['Life expectancy ']\n",
    "features = scaled_data.drop('Life expectancy ',axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIVIDIMOS LA DATA EN TRAIN_TEST\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test, y_train, y_test = train_test_split(features,target,\n",
    "test_size=0.2,\n",
    "random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "source": [
    "# DEFINIENDO LOS MODELOS "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_layer_model():\n",
    "    '''\n",
    "    Red Neuronal de una sola copa\n",
    "    - Optimer : ADAptive Moment (ADAM)\n",
    "    - Metrics : Mean Square Erro (mse), \n",
    "                Mean Absolute Error (mae)\n",
    "    '''\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(32, input_shape=(x_train.shape[1],), activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    \n",
    "    model.compile(loss='mse',\n",
    "    metrics=['mse','mae'],\n",
    "    optimizer=optimizer)\n",
    "\n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = single_layer_model()\n",
    "\n",
    "# PARA VER UN RESUMEN DE NUESTRO MODELO\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VER DE MANERA VISUAL NUESTRO MODELO\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "training_history = model.fit(x_train,\n",
    "                            y_train,\n",
    "                            epochs=num_epochs,\n",
    "                            validation_split=0.2,\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACEMOS Y_PRED\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HALLAMOS R2_SCORE\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZAMOS Y_TEST AL LADO DE Y_PRED\n",
    "pd.DataFrame({'y_test':y_test.values.flatten(),\n",
    "'y_perd':y_pred.flatten(),\n",
    "'error':abs(y_test.values.flatten()-y_pred.flatten())}\n",
    ").sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VER LA CORRELACIÓN DE FORMA MÁS VISUAL \n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(y_test,y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# MULTIPLE LAYERS MODEL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIPLE LAYERS MODEL\n",
    "def multiple_layers_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(32,input_shape=(x_train.shape[1],), activation='relu'),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(4,activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "    metrics=['mae','mse'],\n",
    "    optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multiple_layers_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf seq_logs\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VISUALIZAR LOS LOGS EN UN TENSORBOARD\n",
    "\n",
    "logdir = os.path.join(\"seq_logs\",datetime.datetime.now().strftime(\"%y%m%d-%H%m%S\"))\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(x_train,y_train,\n",
    "            epochs=100,\n",
    "            validation_split=0.2,\n",
    "            batch_size = 100,\n",
    "            callbacks = [tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir seq_logs --port 6050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZAMOS Y_TEST AL LADO DE Y_PRED\n",
    "pd.DataFrame({'y_test':y_test.values.flatten(),\n",
    "'y_perd':y_pred.flatten(),\n",
    "'error':abs(y_test.values.flatten()-y_pred.flatten())}\n",
    ").sample(15)"
   ]
  },
  {
   "source": [
    "# MODEL WITH STOCASTIC GRADIENT DISCENT (SGD)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_with_sgd():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(32, input_shape=(x_train.shape[1],), activation='relu'),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(4, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                    metrics=['mae','mse'],\n",
    "                    optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sgd = model_with_sgd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model_sgd,show_shapes=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "training_history = model_sgd.fit(x_train,\n",
    "                            y_train,\n",
    "                            epochs=num_epochs,\n",
    "                            validation_split=0.2,\n",
    "                            batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sgd.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sgd = model_sgd.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_sgd = r2_score(y_test,y_pred_sgd)\n",
    "r2_sgd"
   ]
  },
  {
   "source": [
    "# RMSPROP"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_with_rmsprop():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(32, input_shape=(x_train.shape[1],), activation='elu'),\n",
    "        tf.keras.layers.Dense(16, activation='elu'),\n",
    "        tf.keras.layers.Dense(4, activation='elu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                    metrics=['mae','mse'],\n",
    "                    optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rmsprop = model_with_rmsprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "training_history = model_rmsprop.fit(x_train,\n",
    "                            y_train,\n",
    "                            epochs=num_epochs,\n",
    "                            validation_split=0.2,\n",
    "                            batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rmsprop.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rmsprop = model_rmsprop.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_rmsprop = r2_score(y_test,y_pred_rmsprop)\n",
    "r2_rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}